---
layout: post
title: "Conjugate-Computation Variational Inference (CVI)"
author: "Kalvik Jakkala"
categories: journal
tags: [machine learning, Bayesian learning]
abstract: "Tutorial on Conjugate-Computation Variational Inference (CVI). A computationally efficient, modular, and parameter efficient generalization of variational inference with gradient descent."
---

## Problem

$$ p(\mathbf{z}|\mathbf{y}) = \frac{p(\mathbf{y}, \mathbf{z})}{\int p(\mathbf{y}, \mathbf{z}) d\mathbf{z}} = \frac{p(\mathbf{y} | \mathbf{z})p(\mathbf{z})}{p(\mathbf{y})} $$

The marginal $p(\mathbf{y})$ is usually computationally intractable because of the integral involved in computing $$\int p(\mathbf{y}, \mathbf{z}) d\mathbf{z}$$.

## Definition of Conjugacy
Suppose $$\mathcal{F}$$ is the class of data distributions
$$p\mathbf{(y\mid z)}$$ parameterized by $$\mathbf{z}$$, and $$\mathcal{P}$$ is the class of prior distributions for $$\mathbf{z}$$, then the class $$\mathcal{P}$$ is conjugate for $$\mathcal{F}$$ if

$$p\mathbf{(z|y)} \in \mathcal{P}, \ \forall p(·|\theta) \in \mathcal{F} \text{ and } p(·) \in \mathcal{P}$$

## Conjugate Model

When the probabilistic graphical model, i.e., the joint distribution $p(\mathbf{y}, \mathbf{z})$ can be decomposed into a prior $p(\mathbf{z})$ which is conjugate to the likelihood $p(\mathbf{y\mid z})$, then the posterior $p(\mathbf{z\mid y})$ is available in closed form. Indeed, the posterior $p(\mathbf{z\mid y})$ be computed using simple computations referned to as conjugage computations. 

Consider the prior and likelihood in the exponential-family distribution with the following natural parametrization:

$$
\begin{aligned}
p(\mathbf{z}) &= h(\mathbf{z}) \exp[\langle \phi(\mathbf{z}), \lambda_\text{prior} \rangle - A(\lambda_\text{prior})] \\
p(\mathbf{y|z}) &= \exp[\langle \phi(\mathbf{z}), \bar{\lambda} \rangle - \bar{A}(\bar{\lambda})] \\
\end{aligned}
$$

here, $h(\mathbf{z})$ is a base measure, $\phi$ is the sufficient statistic, and functions $A$ and $\bar{A}$ are log-partition functions. In such cases, the posterior $p(\mathbf{z\mid y})$ takes the same exponential form as the prior $p(\mathbf{z})$ whose natural parameters are just the sum of the prior and likelihood's natural parameters:

$$
p(\mathbf{z | y}) \propto h(\mathbf{z}) \exp[\langle \phi(\mathbf{z}), \lambda_\text{prior}+\bar{\lambda} \rangle] \\
$$

## Non-Conjugate Model

When the joint distribution $p(\mathbf{y}, \mathbf{z})$ cannot be decomposed into conjugate terms, the posterior becomes difficult to compute. For example, when the prior is Gaussian and the likelihood is non-Gaussian such as a logistic distribution, which can be used to model categorical variables. One approach to get the posterior in such cases it to use variational inference.

### Variational Inference using Stochastic-Gradient Methods

In variational inference (VI), we approximate the posterior $p\mathbf{(z\mid y)}$ with the variational distribution $q(\mathbf{z}; \lambda)$ parametrized by the natural parameters $\lambda$ by minimizing the KL divergence between the posterior and the variational distribution (detailed derivation shown in my tutorial on [variational Gaussian approximation](https://itskalvik.github.io/VGAFreeParams)):

$$
\underbrace{\text{KL}(q(\mathbf{z}) || p(\mathbf{z} | \mathbf{y}))}_\text{Minimize} = \mathbb{E}_{q(\mathbf{z})} [\ln q(\mathbf{z})] - \mathbb{E}_{q(\mathbf{z})} [\ln p(\mathbf{z}, \mathbf{y})] +  \ln p(\mathbf{y})
$$

But the above requires us to compute the intractable marginal $p(\mathbf{y})$, so instead we maximize the following called the expected lower bound (ELBO) which does not include the marginal $p(\mathbf{y})$ and is equivalent to the above KL up to an added constant:

$$
\underbrace{\text{ELBO}}_\text{Maximize} := \mathcal{L}(q(\mathbf{z})) = \mathbb{E}_{q(\mathbf{z})} [\ln p(\mathbf{z}, \mathbf{y})] - \mathbb{E}_{q(\mathbf{z})} [\ln q(\mathbf{z})]
$$

We can optimize the ELBO with respect to the variational distribution's natural parameters $\lambda$ of the $q(\mathbf{z})$ using stochastic-gradient methods, such as the following stochastic-gradient descent algorithm:

$$
\lambda_{t+1} = \lambda_{t} + \rho_t \left[ \hat{\nabla}_\lambda \mathcal{L}(\lambda_t) \right]
$$

here $\hat{\nabla}_\lambda$ are the stochastic gradients of the ELBO $\mathcal{L}(q(\mathbf{z}))$ with respect to the natural parameters $\lambda$ at $\lambda = \lambda_t$.

### Limitations of Stochastic-Gradient Methods

Stochastic-gradient methods can be applied to a wide variety of inference problems and have good scalability. However, a naive application of such methods could have the following limitations:

* The efficiency and rate of convergence might depend on the parameterization used for the variational distribution $q(\mathbf{z})$. Refer to my tutorial on [Variational Gaussian approximation](https://itskalvik.github.io/VGAFreeParams) for more details.

* The parameters $\lambda$ of the variational distribution $q(\mathbf{z})$ exist in a Riemmanian space in which the steepest descent direction is not always aligned with the gradient direction. This is an issue since conventianl gradient methods operate in Euclidean spaces. This is evident from the following alternate formulation of stochastic-gradient descent:

    $$
    \lambda_{t+1} = \text{arg} \max_{\lambda \in \Omega} \langle \lambda, \hat{\nabla}_\lambda \mathcal{L}(\lambda_t) \rangle - \frac{1}{2\rho}||\lambda-\lambda_t||^2
    $$

    where $\Omega$ is the set of valid natural parameters, $\rho$ is the step size and $\mid\mid.\mid\mid$ is the Euclidean norm. The norm term ensures that the new $\lambda_{t+1}$ is close to the previous $\lambda_{t}$. However, since the $\lambda$ parameters do not exist in a Euclidean space, the Euclidean norm could slow the convergence rate of stochastic-gradient descent. This issue is well illustrated by following figure from [Khan and Nielsen, 2018](https://arxiv.org/pdf/1807.04489.pdf):

    <center> <img src="{{ site.github.url }}/assets/img/param_dist.png" width="50%"> </center>

    We see that both cases have the same Euclidean distance even though the top figure has no overlap between the two distributions and the bottom figure has a significant overlap.

* Consider the case when the joint distribution $p(\mathbf{y}, \mathbf{z})$ can be decomposed into a set of conjugate and non-conjugate terms. For instance, when using VI for Gaussian processes, we usually fix the variational distribution $q(\mathbf{z})$ to be a Gaussian and the prior $p(\mathbf{z})$ to also be a Gaussian even if the likelihood is non-Gaussian. In such cases, even though the exact posterior might not belong to the Gaussian distribution, we force conjugacy by fixing the prior and posterior distributions. As such, we can say that the joint distribution $p(\mathbf{y}, \mathbf{z})$ is decomposed into a non-conjugate component (likelihood $p(\mathbf{y \mid z})$) and conjugate component (prior $p(\mathbf{z})$). When considering such problems, it is possible that the conjugate terms in the ELBO might have a closed-form expression and may not require any stochastic approximations.

### Conjugate-Computation Varational Inference (CVI) 

Conjugate-Computation Varational Inference addresses the above mentioned limitations while making the following two assumptions:

#### Assumption 1

The variational distribution $q(\mathbf{z}; \lambda)$ is a minimal exponential-family distribution:

$$
q(\mathbf{z}; \lambda) = h(\mathbf{z}) \exp \left\{ \langle \phi(\mathbf{z}), \lambda \rangle - A(\lambda) \right\}
$$

with $\lambda$ are the natural parameters. Refer to my [tutorial on natural parameters for more details](https://itskalvik.github.io/NaturalParams). The minimal representation implies that there is a one-to-one mapping between the natural parameters $\lambda$ and the mean parameters $\eta := \mathbb{E}_q[\phi(\mathbf{z})]$. Indeed, being able to switch between the natural parametrization and mean parametrization plays a critical role in deriving the CVI method. 

#### Assumption 2

The joint distribution $p(\mathbf{y}, \mathbf{z})$ can be decomposed into a non-conjugate term $\tilde{p}_{nc}$ and a conjugate term $\tilde{p}_c$. The conjugate term $\tilde{p}_c$ takes the same form as the variational distribution $q(\mathbf{z})$:

$$
\begin{aligned}
p(\mathbf{y}, \mathbf{z}) & \propto \tilde{p}_{nc}(\mathbf{y, z})\tilde{p}_c(\mathbf{y, z}) \\
\tilde{p}_c(\mathbf{y, z}) & \propto h(\mathbf{z}) \exp {\langle \phi(\mathbf{z}), \lambda_c \rangle}
\end{aligned}
$$

Note that these assumptions not particularly restrictive. Indeed, the exponential-family distribution is a rich class of distributions, which includes the Gaussian distribution. Also, it is common to a assume Gaussian prior when using VI, which together with Assumption 1, satisfies Assumption 2. However, if there is no conjugate term in the joint distribution $p(\mathbf{y}, \mathbf{z})$, CVI might not have any advantage over stochastic-gradient based VI.

#### Main Theorem
Let us assume that the joint distribution $p(\mathbf{y}, \mathbf{z})$ can be decomposed into the following non-conjugate and conjugate terms:

$$
\begin{aligned}
p(\mathbf{y}, \mathbf{z}) & \propto \tilde{p}_{nc}(\mathbf{y, z}) \quad \ \ \tilde{p}_c(\mathbf{y, z}) \\
                          & \propto \underbrace{p(\mathbf{y|z})}_{\substack{\text{Non-Gaussian} \\ \text{Likelihood}}} \ \underbrace{p(\mathbf{z})}_\text{Gaussian Prior}
\end{aligned}
$$

The original derivation is more general and does not limit the likelihood to be the non-conjugate term and the prior to be the conjugate term of the joint distribution $p(\mathbf{y}, \mathbf{z})$. However, I found it easier to follow the derivation by assuming the above realizations of the non-conjugate and conjugate terms.

The CVI method derivation starts by considering the following mirror-descent algorithm which replaces the Euclidean norm in the stochastic-gradient descent algorithm with the Bergman divergence and operates on the mean parametization $\eta$ of the variational distribution $q(\mathbf{z})$ to optimize the ELBO:

$$
\eta_{t+1} = \text{arg} \max_{\eta \in \mathcal{M}} \langle \eta, \hat{\nabla}_\eta \tilde{\mathcal{L}}(\eta_t) \rangle - \frac{1}{\beta_t} \mathbb{B}_{A^*}(\eta||\eta_t)
$$

here $\tilde{\mathcal{L}}$ is the ELBO that operates on the mean parameters $\eta$ of the variational distribution. $A^{\*}(\eta)$ is the convex-conjugate of the log-partition function $A(\lambda)$, $\mathbb{B}_{A^\*}$ is the bergman divergence induced by $A^*$ over $\mathcal{M}$, and $\beta_t > 0$ is the step size. 

The exact form of the Bergman divergence varies based on the space in which the variables belong to. In our case, for exponential-family distributions, the Bergman divergence is equal to the KL divergence (Refer to [Amari, 2016](https://link.springer.com/book/10.1007/978-4-431-55978-8) chapter 1 for the detailed derivation.), giving us the following updates: 

$$
\eta_{t+1} = \text{arg} \max_{\eta \in \mathcal{M}} \langle \eta, \hat{\nabla}_\eta \tilde{\mathcal{L}}(\eta_t) \rangle - \frac{1}{\beta_t} \text{KL}(q(\mathbf{z};\eta)||q(\mathbf{z};\eta_t))
$$

Using the KL term to regularize our updates instead of using the Euclidean norm makes more sense, as the KL divergence is able to better capture the distance between two distributions (note the the KL divergence is assymetric). The above updates are also equal to using natural gradient descent in the natural parameter space $\Omega$, in which the gradient update are scaled by the fisher information matrix $\mathbf{F}(\lambda)$ to align the gradients with the steepest descent direction when operating in Riemannian spaces as we do here:

$$
\begin{aligned}
\lambda_{t+1} &= \text{arg} \max_{\lambda \in \Omega} \langle \lambda, \hat{\nabla}_\lambda \mathcal{L}(\lambda_t) \rangle - \frac{1}{2\rho_t} (\lambda - \lambda_t)^\top \mathbf{F}(\lambda_t) (\lambda - \lambda_t) \\
\implies & \lambda_{t+1} =  \lambda_t + \rho_t \underbrace{[\mathbf{F}(\lambda_t)]^{-1} \hat{\nabla}_\lambda \mathcal{L}(\lambda_t)}_\text{natural gradient $\tilde{\nabla}_\lambda$}
\end{aligned}
$$

here the fisher information matrix $$\mathbf{F}(\lambda) = \mathbb{E}_{q_\lambda}[\nabla_\lambda \log q_\lambda(\mathbf{z}) \nabla_\lambda \log q_\lambda(\mathbf{z})^\top]$$. However, [Khan and lin, 2017](https://arxiv.org/abs/1703.04265) showed that we do not have to explicitly compute the fisher information matrix and invert it to computing the natural gradients for the conjugate terms of the ELBO $\mathcal{L}$. Indeed, we can leverage the one-to-one mapping between the mean and natural parametrization of exponential-family distributions to get the following natural gradients $\tilde{\nabla}_\lambda$:

$$
\begin{aligned}
\tilde{\nabla}_\lambda \mathbb{E}_q \left[ \log \frac{p(\mathbf{z}; \lambda_\text{prior})}{q(\mathbf{z}; \lambda)} \right] &= [\mathbf{F}(\lambda)]^{-1} \hat{\nabla}\mathbb{E}_q [\phi(\mathbf{z})^\top (\lambda_\text{prior}-\lambda) + A(\lambda)] \\
&= \lambda_\text{prior} - \lambda
\end{aligned}
$$
