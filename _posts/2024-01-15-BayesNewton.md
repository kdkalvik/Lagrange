---
layout: post
title: "Bayes-Newton Methods for Approximate Bayesian Inference"
author: "Kalvik Jakkala"
categories: journal
tags: [machine learning, Bayesian learning]
abstract: "Tutorial on Bayes-Newton Methods for Approximate Bayesian Inference with PSD Guarantees."
---

## Outline

* [ ] Problem
* [ ] Formulation
* [ ] BLR
* [ ] Bonnet and Price's Theorem
* [ ] Newton's Method & Laplace Approx.
* [ ] Bayes-Newton (VI)
* [ ] Limitations
* [ ] Bayes-Gauss-Newton (VI)
* [ ] Bayes-Quasi-Newton (VI)
* [ ] PSD constraints via Riemannian Gradients (VI)

---

# References

* [Amari's bookâ€”Information Geometry and Its Applications](https://link.springer.com/book/10.1007/978-4-431-55978-8)
* [Amari's paper on natural gradients](https://direct.mit.edu/neco/article-abstract/10/2/251/6143/Natural-Gradient-Works-Efficiently-in-Learning?redirectedFrom=fulltext)
* [Khan and Lin's paper on Conjugate-computation Variational Inference (CVI)](https://arxiv.org/abs/1703.04265)
* [Khan and Nielsen's paper on natural gradient descent](https://arxiv.org/abs/1807.04489)
* [Khan's slides on CVI](https://bigdata.nii.ac.jp/eratokansyasai4/wp-content/uploads/2017/09/4_Emitiyaz-Khan.pdf)
* [David Blei's tutorial on Variational Inference](https://arxiv.org/abs/1601.00670)
* [Khan and Rue's paper on the bayesian learning rule](https://www.jmlr.org/papers/volume24/22-0291/22-0291.pdf)
* [Wilkinson et al. Bayes-Newton Methods for Approximate Bayesian Inference with PSD Guarantees](https://www.jmlr.org/papers/volume24/21-1298/21-1298.pdf)